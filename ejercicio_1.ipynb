{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eeb4be9",
   "metadata": {},
   "source": [
    "# Ejercicio #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\fundamentos-llms\\fund-llms\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import certifi\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a514ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59e4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\fundamentos-llms\\fund-llms\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\uif29726\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a cargar una version preentrenada de BERT\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Mover el modelo a GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69be42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de parámetros: 199\n"
     ]
    }
   ],
   "source": [
    "named_params = list(model.named_parameters())\n",
    "\n",
    "# Imprimir la cantidad de parámetros y sus nombres\n",
    "print(f\"Total de parámetros: {len(named_params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6174cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Capa de Embedding======\n",
      "\n",
      "embeddings.word_embeddings.weight                       (30522, 768)\n",
      "embeddings.position_embeddings.weight                     (512, 768)\n",
      "embeddings.token_type_embeddings.weight                     (2, 768)\n",
      "embeddings.LayerNorm.weight                                   (768,)\n",
      "embeddings.LayerNorm.bias                                     (768,)\n",
      "\n",
      "======Primer Encoder======\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.query.bias                     (768,)\n",
      "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
      "encoder.layer.0.attention.self.key.bias                       (768,)\n",
      "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.value.bias                     (768,)\n",
      "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
      "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
      "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
      "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
      "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
      "encoder.layer.0.output.dense.bias                             (768,)\n",
      "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
      "encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
      "\n",
      "======Segundo Encoder======\n",
      "\n",
      "pooler.dense.weight                                       (768, 768)\n",
      "pooler.dense.bias                                             (768,)\n"
     ]
    }
   ],
   "source": [
    "# Imprimir la capa de embedding\n",
    "print(\"======Capa de Embedding======\\n\")\n",
    "for p in named_params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].shape))))\n",
    "\n",
    "# Imprimir el primer encoder\n",
    "print(\"\\n======Primer Encoder======\\n\")\n",
    "for p in named_params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].shape))))\n",
    "\n",
    "# Imprimir el segundo encoder\n",
    "print(\"\\n======Segundo Encoder======\\n\")\n",
    "for p in named_params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18361804",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab645e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 27178,  8747,  7459,  2000,  3642,  1999, 18750,   102]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Othon loves to code in Python\", return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52bbac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2213,  0.4771, -0.3867,  ..., -0.1356,  0.6587,  0.4269],\n",
      "         [ 0.8593,  0.1995,  0.5775,  ...,  0.1166,  0.9928,  0.0974],\n",
      "         [-0.0088,  0.0421, -0.0123,  ...,  0.1461,  0.5752, -0.0631],\n",
      "         ...,\n",
      "         [-0.8762,  0.4043, -0.4904,  ..., -0.6379, -0.3283,  0.4589],\n",
      "         [-0.1807,  0.6547, -0.7054,  ..., -0.2865,  0.2484, -0.2530],\n",
      "         [ 0.6761,  0.0906, -0.2353,  ...,  0.1048, -0.7769, -0.2543]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Pasamos los tokens a través del modelo\n",
    "input_ids = tokenizer.encode(\"Othon loves to code in Python\", return_tensors='pt')\n",
    "input_ids = input_ids.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Extraemos las representaciones de la última capa\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46d01ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta capa en particular esta entrenada para generar una representación\n",
    "# de la secuencia completa\n",
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49f51f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPooler(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a13d43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomaremos la representación final del token [CLS] para calcular la similitud\n",
    "cls_embedding = outputs.last_hidden_state[:, 0, :].unsqueeze(0)\n",
    "\n",
    "cls_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5367d8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pooler(cls_embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b95156d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si corremos el embedding de CLS a través de la capa pooler obtenemos\n",
    "# la misma representación que si lo hacemos directamente\n",
    "\n",
    "(model.pooler(cls_embedding) == outputs.pooler_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c00d90de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de parámetros del modelo: 109,482,240\n"
     ]
    }
   ],
   "source": [
    "# De aquí podemos sacar tambien la cantidad total de parámetros del modelo\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total de parámetros del modelo: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8775b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fund-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
