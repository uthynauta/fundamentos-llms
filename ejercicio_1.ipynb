{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eeb4be9",
   "metadata": {},
   "source": [
    "# Ejercicio #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6e2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a514ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\fundamentos-llms\\fund-llms\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f4644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda\n",
      "Nombre del dispositivo: NVIDIA T1200 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Agregamos una prueba para verificar si estamos usando cuda o cpu\n",
    "# e imprimimos el dispositivo que se está utilizando así como su nombre\n",
    "\n",
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Dispositivo utilizado:\", \"cuda\" if device == 0 else \"cpu\")\n",
    "if device == 0:\n",
    "    print(\"Nombre del dispositivo:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59e4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a cargar una version preentrenada de BERT\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Mover el modelo a GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69be42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de parámetros: 199\n"
     ]
    }
   ],
   "source": [
    "named_params = list(model.named_parameters())\n",
    "\n",
    "# Imprimir la cantidad de parámetros y sus nombres\n",
    "print(f\"Total de parámetros: {len(named_params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6174cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Capa de Embedding======\n",
      "\n",
      "embeddings.word_embeddings.weight                       (30522, 768)\n",
      "embeddings.position_embeddings.weight                     (512, 768)\n",
      "embeddings.token_type_embeddings.weight                     (2, 768)\n",
      "embeddings.LayerNorm.weight                                   (768,)\n",
      "embeddings.LayerNorm.bias                                     (768,)\n",
      "\n",
      "======Primer Encoder======\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.query.bias                     (768,)\n",
      "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
      "encoder.layer.0.attention.self.key.bias                       (768,)\n",
      "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.value.bias                     (768,)\n",
      "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
      "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
      "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
      "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
      "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
      "encoder.layer.0.output.dense.bias                             (768,)\n",
      "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
      "encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
      "\n",
      "======Segundo Encoder======\n",
      "\n",
      "pooler.dense.weight                                       (768, 768)\n",
      "pooler.dense.bias                                             (768,)\n"
     ]
    }
   ],
   "source": [
    "# Imprimir la capa de embedding\n",
    "print(\"======Capa de Embedding======\\n\")\n",
    "for p in named_params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].shape))))\n",
    "\n",
    "# Imprimir el primer encoder\n",
    "print(\"\\n======Primer Encoder======\\n\")\n",
    "for p in named_params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].shape))))\n",
    "\n",
    "# Imprimir el segundo encoder\n",
    "print(\"\\n======Segundo Encoder======\\n\")\n",
    "for p in named_params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18361804",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab645e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 27178,  8747,  7459,  2000,  3642,  1999, 18750,   102]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Othon loves to code in Python\", return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52bbac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2213,  0.4771, -0.3867,  ..., -0.1356,  0.6587,  0.4269],\n",
      "         [ 0.8593,  0.1995,  0.5775,  ...,  0.1166,  0.9928,  0.0974],\n",
      "         [-0.0088,  0.0421, -0.0123,  ...,  0.1461,  0.5752, -0.0631],\n",
      "         ...,\n",
      "         [-0.8762,  0.4043, -0.4904,  ..., -0.6379, -0.3283,  0.4589],\n",
      "         [-0.1807,  0.6547, -0.7054,  ..., -0.2865,  0.2484, -0.2530],\n",
      "         [ 0.6761,  0.0906, -0.2353,  ...,  0.1048, -0.7769, -0.2543]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\fundamentos-llms\\fund-llms\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:412: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# Pasamos los tokens a través del modelo\n",
    "input_ids = tokenizer.encode(\"Othon loves to code in Python\", return_tensors='pt')\n",
    "input_ids = input_ids.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Extraemos las representaciones de la última capa\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d58a46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d01ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta capa en particular esta entrenada para generar una representación\n",
    "# de la secuencia completa\n",
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49f51f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPooler(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a13d43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomaremos la representación final del token [CLS] para calcular la similitud\n",
    "cls_embedding = outputs.last_hidden_state[:, 0, :].unsqueeze(0)\n",
    "\n",
    "cls_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5367d8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pooler(cls_embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b95156d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si corremos el embedding de CLS a través de la capa pooler obtenemos\n",
    "# la misma representación que si lo hacemos directamente\n",
    "\n",
    "(model.pooler(cls_embedding) == outputs.pooler_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00d90de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de parámetros del modelo: 109,482,240\n"
     ]
    }
   ],
   "source": [
    "# De aquí podemos sacar tambien la cantidad total de parámetros del modelo\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total de parámetros del modelo: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8775b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fund-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
