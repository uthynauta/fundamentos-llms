{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143d6b2a",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d6d19",
   "metadata": {},
   "source": [
    "Vamos a explorar como funciona el tokenizador específico que utiliza BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\fundamentos-llms\\fund-llms\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6bb33c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario de BERT: 30,522 tokens\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carguemos el tokenizador de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Echemos un vistazo a la longitud del vocabulario\n",
    "vocab_size = len(tokenizer)\n",
    "print(f\"Vocabulario de BERT: {vocab_size:,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5ddb7",
   "metadata": {},
   "source": [
    "Se pueden tokenizar frases o listas de frases para procesar por lotes o _batches_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd15ebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2057,  2024,  1996,  3966,  1010,  2026,  2814,  1012,   102],\n",
      "        [  101,  1996, 13448,  2003,  9361,  2026,  4923,  4646,  1012,   102]])\n"
     ]
    }
   ],
   "source": [
    "# Vamos a tokenizar un par de oraciones para ver cómo funciona\n",
    "\n",
    "sentences = [\n",
    "    \"We are the champions, my friends.\",\n",
    "    \"The banker is checking my credit application.\"\n",
    "]\n",
    "\n",
    "# Tokenización en lote\n",
    "batch = tokenizer(sentences, add_special_tokens=True, padding=True, \n",
    "                  truncation=True, return_tensors='pt')\n",
    "\n",
    "print(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b76848",
   "metadata": {},
   "source": [
    "Volvamos a las frases originales para ver cuál es el procesamiento que hace el tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2b2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'we', 'are', 'the', 'champions', ',', 'my', 'friends', '.', '[SEP]']\n",
      "['[CLS]', 'the', 'banker', 'is', 'checking', 'my', 'credit', 'application', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "for sequence in batch['input_ids']:\n",
    "    tokens = tokenizer.convert_ids_to_tokens(sequence)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972885a0",
   "metadata": {},
   "source": [
    "Intentemos con una palabra que no está en el vocabulario de BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3baf1afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Othon\" NO está en el vocabulario.\n"
     ]
    }
   ],
   "source": [
    "word = \"Othon\"\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "if word in vocab:\n",
    "    print(f'\"{word}\" está en el vocabulario.')\n",
    "else:\n",
    "    print(f'\"{word}\" NO está en el vocabulario.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582ce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 27178,  8747, 14523,  2058,  1996, 13971,  3899,  1012,   102]])\n",
      "['[CLS]', 'ot', '##hon', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "ood_example = \"Othon jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenización del ejemplo OOD\n",
    "ood_tokens = tokenizer(ood_example, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "print(ood_tokens['input_ids'])\n",
    "\n",
    "ood_sentence = tokenizer.convert_ids_to_tokens(ood_tokens['input_ids'][0])\n",
    "print(ood_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80e35c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 27178,  8747, 14523,  2058,  1996, 13971,  3899,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Veamos ademas de los input_ids qué otra información nos entrega el tokenizador\n",
    "print(ood_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a950f",
   "metadata": {},
   "source": [
    "Utilizaremos ahora los embeddings para estudiar cómo se codifican las palabras y conceptos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d457611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_sentence = \"I love my pet python\"\n",
    "coding_sentence = \"I love coding in python\"\n",
    "\n",
    "# Tokenización de las oraciones\n",
    "pet_tokens = tokenizer(pet_sentence, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "coding_tokens = tokenizer(coding_sentence, add_special_tokens=True, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "241e414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice de 'python' en la frase de mascota: 5\n",
      "Índice de 'python' en la frase de programación: 5\n"
     ]
    }
   ],
   "source": [
    "# Verificamos los indices de las palabras python en ambas frases\n",
    "pet_python_index = pet_tokens['input_ids'][0].tolist().index(tokenizer.convert_tokens_to_ids('python')) \n",
    "coding_python_index = coding_tokens['input_ids'][0].tolist().index(tokenizer.convert_tokens_to_ids('python'))\n",
    "\n",
    "print(f\"Índice de 'python' en la frase de mascota: {pet_python_index}\")\n",
    "print(f\"Índice de 'python' en la frase de programación: {coding_python_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "14a0fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora obtendremos los embeddings de BERT para estas oraciones\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Mover el modelo a GPU si está disponible\n",
    "model = model.to(device)\n",
    "\n",
    "# Pasamos los tokens por el modelo para obtener los embeddings con contexto de las palabras \"python\"\n",
    "with torch.no_grad():\n",
    "    pet_embedding = model(**pet_tokens).last_hidden_state[0, pet_python_index, :].cpu().numpy()\n",
    "    coding_embedding = model(**coding_tokens).last_hidden_state[0, coding_python_index, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b7f999c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a comparar los embeddings de las dos oraciones con las palabras \"snake\" y programming\"\n",
    "# No olvidar el token de [CLS] al inicio de las oraciones\n",
    "\n",
    "with torch.no_grad():\n",
    "    snake_embedding = model(**tokenizer(\"snake\", return_tensors='pt').to(device)).last_hidden_state[0, 1, :].cpu().numpy()\n",
    "    programming_embedding = model(**tokenizer(\"programming\", return_tensors='pt').to(device)).last_hidden_state[0, 1, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52ddb2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer(\"snake\", return_tensors='pt').to(device)).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d9fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud entre 'python' en la frase de mascota y 'snake': 0.6929\n",
      "Similitud entre 'python' en la frase de programación y 'programming': 0.5615\n",
      "\n",
      "Similitud entre 'python' en la frase de programación y 'snake': 0.5843\n",
      "Similitud entre 'python' en la frase de mascota y 'programming': 0.4986\n"
     ]
    }
   ],
   "source": [
    "# Comparar los embeddings que suponemos similares\n",
    "similarity_pet_snake = cosine_similarity([pet_embedding], [snake_embedding])[0][0]\n",
    "similarity_coding_programming = cosine_similarity([coding_embedding], [programming_embedding])[0][0]\n",
    "\n",
    "print(f\"Similitud entre 'python' en la frase de mascota y 'snake': {similarity_pet_snake:.4f}\")\n",
    "print(f\"Similitud entre 'python' en la frase de programación y 'programming': {similarity_coding_programming:.4f}\")\n",
    "\n",
    "# Ahora comparemos entre embeddings que suponemos no similares\n",
    "similarity_pet_programming = cosine_similarity([pet_embedding], [programming_embedding])[0][0]\n",
    "similarity_coding_snake = cosine_similarity([coding_embedding], [snake_embedding])[0][0]\n",
    "\n",
    "print(f\"\\nSimilitud entre 'python' en la frase de programación y 'snake': {similarity_coding_snake:.4f}\")\n",
    "print(f\"Similitud entre 'python' en la frase de mascota y 'programming': {similarity_pet_programming:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e5438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fund-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
